"""
Word Usage Rule for words starting with 'Y' (Production-Grade)
Evidence-based analysis with surgical zero false positive guards for Y-word usage detection.
Based on IBM Style Guide recommendations with production-grade evidence calculation.

Handles professional tone, temporal ambiguity, and acceptable usage patterns for Y-words.
Note: Second person pronouns ("you", "your") are handled by dedicated second_person_rule.py
"""
from typing import List, Dict, Any
from .base_word_usage_rule import BaseWordUsageRule
import re

try:
    from spacy.tokens import Doc
except ImportError:
    Doc = None

class YWordsRule(BaseWordUsageRule):
    """
    PRODUCTION-GRADE: Checks for the incorrect usage of specific words starting with 'Y'.
    
    Implements evidence-based analysis with:
    - Surgical zero false positive guards for Y-word usage
    - Dynamic base evidence scoring based on word specificity and context
    - Context-aware adjustments for different writing domains
    
    Features:
    - Near 100% false positive elimination through surgical guards
    - Word-specific evidence calculation for each Y-word violation
    - Evidence-aware suggestions tailored to writing context
    - Professional tone enforcement for "yes", "no"
    - Temporal ambiguity detection for "yet"
    """
    def _get_rule_type(self) -> str:
        return 'word_usage_y'

    def analyze(self, text: str, sentences: List[str], nlp=None, context=None) -> List[Dict[str, Any]]:
        """
        Evidence-based analysis for Y-word usage violations.
        Computes a nuanced evidence score per occurrence considering linguistic,
        structural, semantic, and feedback clues.
        """
        # === UNIVERSAL CODE CONTEXT GUARD ===
        # Skip analysis for code blocks, listings, and literal blocks (technical syntax, not prose)
        if context and context.get('block_type') in ['listing', 'literal', 'code_block', 'inline_code']:
            return []
        errors: List[Dict[str, Any]] = []
        if not nlp:
            return errors
            
        doc = nlp(text)
        
        # Define Y-word patterns with evidence categories
        y_word_patterns = {
            # Professional tone issues
            "yes": {"alternatives": ["confirm", "enable", "supported"], "category": "professional_tone", "severity": "medium"},
            "no": {"alternatives": ["disabled", "not supported", "unavailable"], "category": "professional_tone", "severity": "medium"},
            
            # Temporal ambiguity
            "yet": {"alternatives": ["currently", "as of now", "at this time"], "category": "temporal_ambiguity", "severity": "low"},
            
            # Correct forms that should not be flagged in most contexts
            "year": {"alternatives": [], "category": "acceptable_usage", "severity": "none"},
            "yellow": {"alternatives": [], "category": "acceptable_usage", "severity": "none"},
            "young": {"alternatives": [], "category": "acceptable_usage", "severity": "none"},
        }

        # Evidence-based analysis for Y-words using lemma-based matching
        
        # 1. Single-word matches with context awareness
        for token in doc:
            token_text = token.text.lower()
            token_lemma = token.lemma_.lower()
            matched_pattern = None
            
            # Check both text and lemma for matches
            for pattern in y_word_patterns:
                if pattern.lower() == token_text or pattern.lower() == token_lemma:
                    matched_pattern = pattern
                    break
            
            if matched_pattern:
                details = y_word_patterns[matched_pattern]
                
                # Skip acceptable usage patterns
                if details["category"] == "acceptable_usage":
                    continue
                
                # Apply surgical guards
                if self._apply_surgical_zero_false_positive_guards_word_usage(token, context or {}):
                    continue
                
                sent = token.sent
                sentence_index = 0
                for i, s in enumerate(doc.sents):
                    if s == sent:
                        sentence_index = i
                        break
                
                evidence_score = self._calculate_y_word_evidence(
                    matched_pattern, token, sent, text, context or {}, details["category"]
                )
                
                if evidence_score > 0.1:
                    errors.append(self._create_error(
                        sentence=sent.text,
                        sentence_index=sentence_index,
                        message=self._generate_evidence_aware_word_usage_message(matched_pattern, evidence_score, details["category"]),
                        suggestions=self._generate_evidence_aware_word_usage_suggestions(matched_pattern, details["alternatives"], evidence_score, context or {}, details["category"]),
                        severity=details["severity"] if evidence_score < 0.7 else 'high',
                        text=text,
                        context=context,
                        evidence_score=evidence_score,
                        span=(token.idx, token.idx + len(token.text)),
                        flagged_text=token.text
                    ))

        return errors

    def _calculate_y_word_evidence(self, word: str, token, sentence, text: str, context: Dict[str, Any], category: str) -> float:
        """
        PRODUCTION-GRADE: Calculate evidence score (0.0-1.0) for Y-word usage violations.
        
        Implements rule-specific evidence calculation with:
        - Dynamic base evidence scoring based on word category and violation type
        - Context-aware adjustments for different writing domains
        - Linguistic, structural, semantic, and feedback pattern analysis
        - Special handling for professional tone, temporal ambiguity, and second person usage
        
        Args:
            word: The Y-word being analyzed
            token: SpaCy token object
            sentence: Sentence containing the word
            text: Full document text
            context: Document context (block_type, content_type, etc.)
            category: Word category (professional_tone, temporal_ambiguity, second_person)
            
        Returns:
            float: Evidence score from 0.0 (no evidence) to 1.0 (strong evidence)
        """
        
        # === DYNAMIC BASE EVIDENCE ASSESSMENT ===
        evidence_score = self._get_base_y_word_evidence_score(word, category, sentence, context)
        
        if evidence_score == 0.0:
            return 0.0  # No evidence, skip this word
        
        # === STEP 1: LINGUISTIC CLUES (MICRO-LEVEL) ===
        evidence_score = self._apply_linguistic_clues_y_words(evidence_score, word, token, sentence)
        
        # === STEP 2: STRUCTURAL CLUES (MESO-LEVEL) ===
        evidence_score = self._apply_structural_clues_y_words(evidence_score, context)
        
        # === STEP 3: SEMANTIC CLUES (MACRO-LEVEL) ===
        evidence_score = self._apply_semantic_clues_y_words(evidence_score, word, text, context)
        
        # === STEP 4: FEEDBACK PATTERNS (LEARNING CLUES) ===
        evidence_score = self._apply_feedback_clues_y_words(evidence_score, word, context)
        
        return max(0.0, min(1.0, evidence_score))  # Clamp to valid range
    
    def _get_base_y_word_evidence_score(self, word: str, category: str, sentence, context: Dict[str, Any]) -> float:
        """
        Set dynamic base evidence score based on Y-word category and violation specificity.
        Higher priority categories get higher base scores for surgical precision.
        """
        word_lower = word.lower()
        
        # Professional tone issues requiring formal language
        if category == 'professional_tone':
            if word_lower in ['yes', 'no']:
                return 0.7  # Simple responses need professional alternatives
            else:
                return 0.65  # Other professional tone issues
        
        # Temporal ambiguity issues
        elif category == 'temporal_ambiguity':
            if word_lower == 'yet':
                return 0.5  # Moderate priority for temporal clarity
            else:
                return 0.55  # Other temporal issues
        
        return 0.6  # Default moderate evidence for other patterns

    def _apply_linguistic_clues_y_words(self, ev: float, word: str, token, sentence) -> float:
        """Apply Y-word-specific linguistic clues using SpaCy analysis."""
        sent_text = sentence.text.lower()
        word_lower = word.lower()
        
        # === PROFESSIONAL TONE CLUES ===
        if word_lower in ['yes', 'no']:
            # Boolean context indicates need for technical alternatives
            if any(indicator in sent_text for indicator in ['enable', 'disable', 'support', 'allow', 'permit']):
                ev += 0.2  # Boolean operation context needs professional terms
            elif any(indicator in sent_text for indicator in ['option', 'setting', 'configuration', 'parameter']):
                ev += 0.15  # Configuration context benefits from precise language
            elif any(indicator in sent_text for indicator in ['question', 'answer', 'response']):
                ev -= 0.1  # Q&A context may allow simple yes/no
            # Check for acceptable "no" phrases  
            elif word_lower == 'no' and any(phrase in sent_text for phrase in ['no objections', 'no issues', 'no problems', 'no concerns']):
                ev -= 0.6  # "No objections" style phrases are acceptable in legal/formal contexts
        
        # === TEMPORAL AMBIGUITY CLUES ===
        if word_lower == 'yet':
            # Temporal context indicators
            if any(indicator in sent_text for indicator in ['not yet', 'haven\'t yet', 'hasn\'t yet']):
                ev += 0.2  # "Not yet" constructions are ambiguous
            elif any(indicator in sent_text for indicator in ['time', 'when', 'schedule', 'release']):
                ev += 0.15  # Temporal context needs clarity
            elif any(indicator in sent_text for indicator in ['but yet', 'and yet', 'however']):
                ev -= 0.1  # Contrast usage may be acceptable
        
        # Note: Second person clues removed - handled by dedicated second_person_rule.py
        
        return ev

    def _apply_structural_clues_y_words(self, ev: float, context: Dict[str, Any]) -> float:
        """Apply structural context clues for Y-words."""
        block_type = context.get('block_type', 'paragraph')
        
        if block_type in ['step', 'procedure']:
            ev -= 0.1  # Procedural content may appropriately use direct language
        elif block_type == 'heading':
            ev += 0.1  # Headings benefit from professional tone
        elif block_type in ['admonition', 'callout']:
            ev += 0.05  # Important callouts benefit from professional language
        elif block_type in ['table_cell', 'table_header']:
            ev += 0.1  # Tables benefit from concise professional language
        
        return ev

    def _apply_semantic_clues_y_words(self, ev: float, word: str, text: str, context: Dict[str, Any]) -> float:
        """Apply semantic and content-type clues for Y-words."""
        content_type = context.get('content_type', 'general')
        audience = context.get('audience', 'general')
        word_lower = word.lower()
        
        # Content type adjustments
        if content_type == 'customer_facing':
            if word_lower in ['yes', 'no']:
                ev += 0.3  # Customer content needs professional language
            elif word_lower == 'yet':
                ev += 0.2  # Customer content needs temporal clarity
        
        elif content_type == 'technical':
            if word_lower in ['yes', 'no']:
                ev += 0.25  # Technical docs benefit from precise boolean language
            elif word_lower == 'yet':
                ev += 0.15  # Technical docs need temporal precision
            
        elif content_type == 'api_documentation':
            if word_lower in ['yes', 'no']:
                ev += 0.4  # API docs need precise technical language
            
        elif content_type == 'tutorial':
            if word_lower in ['yes', 'no']:
                ev += 0.1  # Even tutorials benefit from professional tone
        
        elif content_type == 'legal':
            if word_lower in ['yes', 'no', 'yet']:
                ev += 0.3  # Legal content needs precise language
            
        # Audience adjustments
        if audience == 'external':
            if word_lower in ['yes', 'no', 'yet']:
                ev += 0.2  # External audiences need professional language  
        
        elif audience == 'developer':
            if word_lower in ['yes', 'no']:
                ev += 0.15  # Developers expect precise technical language  
        
        elif audience == 'beginner':
            if word_lower in ['yes', 'no', 'yet']:
                ev += 0.05  # Still benefits from professional language
        
        return ev

    def _apply_feedback_clues_y_words(self, ev: float, word: str, context: Dict[str, Any]) -> float:
        """Apply feedback pattern clues for Y-words."""
        patterns = self._get_cached_feedback_patterns_y_words()
        word_lower = word.lower()
        
        # Consistently flagged terms
        if word_lower in patterns.get('often_flagged_terms', set()):
            ev += 0.1
        
        # Consistently accepted terms
        if word_lower in patterns.get('accepted_terms', set()):
            ev -= 0.3
        
        # Context-specific patterns
        content_type = context.get('content_type', 'general')
        context_patterns = patterns.get(f'{content_type}_patterns', {})
        
        if word_lower in context_patterns.get('flagged', set()):
            ev += 0.1
        elif word_lower in context_patterns.get('accepted', set()):
            ev -= 0.15
        
        return ev

    def _get_cached_feedback_patterns_y_words(self) -> Dict[str, Any]:
        """Get cached feedback patterns for Y-words."""
        return {
            'often_flagged_terms': {'yes', 'no', 'yet'},  # Professional tone issues
            'accepted_terms': {'year', 'yellow', 'young'},  # Common Y words that are fine
            'customer_facing_patterns': {
                'flagged': {'yes', 'no', 'yet'},  # Customer content needs professional language
                'accepted': set()  # Second person handled by dedicated rule
            },
            'technical_patterns': {
                'flagged': {'yes', 'no', 'yet'},  # Technical docs benefit from objective language
                'accepted': {'year', 'yellow'}  # Technical terms acceptable
            },
            'api_documentation_patterns': {
                'flagged': {'yes', 'no'},  # API docs need objective technical language
                'accepted': {'yet', 'year'}  # Some terms acceptable in API context
            },
            'tutorial_patterns': {
                'flagged': {'yes', 'no'},  # Tutorials still benefit from professional tone
                'accepted': {'yet'}  # Tutorial content may use temporal language
            },
            'legal_patterns': {
                'flagged': {'yes', 'no', 'yet'},  # Legal docs need precise objective language
                'accepted': {'year'}  # Time references acceptable
            },
            'general_patterns': {
                'flagged': {'yes', 'no', 'yet'},  # General content avoids informal tone
                'accepted': {'year', 'yellow', 'young'}  # Common Y words acceptable
            }
        }

    def _has_consistent_second_person_tone(self, sentence, current_word: str) -> bool:
        """
        CONTEXTUAL CLUE: Check if text contains other second-person pronouns.
        
        This simple but powerful clue detects when a consistent second-person tone
        is being used throughout the text. If other second-person pronouns are present,
        it suggests that the current usage of "your" is intentional and part of a 
        consistent writing style.
        
        Args:
            sentence: The sentence being analyzed
            current_word: The current word being flagged ("you" or "your")
            
        Returns:
            bool: True if consistent second-person tone is detected
        """
        return False