"""
API Routes Module
Contains all Flask route handlers for the web application.
Handles file uploads, text analysis, AI rewriting, and health checks.
"""

import os
import time
import logging
from datetime import datetime
from flask import render_template, request, jsonify, flash, redirect, url_for, send_file, session
from werkzeug.utils import secure_filename
from werkzeug.exceptions import RequestEntityTooLarge
from io import BytesIO

from config import Config
from .websocket_handlers import emit_progress, emit_completion

logger = logging.getLogger(__name__)


def setup_routes(app, document_processor, style_analyzer, ai_rewriter, database_service=None):
    """Setup all API routes for the Flask application with database integration."""
    
    # Add request logging and session management middleware
    @app.before_request
    def log_request_info():
        """Log all incoming requests and ensure database session exists."""
        # Skip logging and session creation for health check endpoints
        if request.path in ['/health', '/health/detailed']:
            return
        
        print(f"\nüì• INCOMING REQUEST: {request.method} {request.path}")
        if request.method == 'POST':
            print(f"   üìã Content-Type: {request.content_type}")
            print(f"   üìã Content-Length: {request.content_length}")
            if request.is_json:
                print(f"   üìã JSON Data Keys: {list(request.json.keys()) if request.json else 'None'}")
        
        # Ensure database session exists for data persistence
        if database_service and 'db_session_id' not in session:
            try:
                db_session_id = database_service.create_user_session(
                    user_agent=request.headers.get('User-Agent'),
                    ip_address=request.remote_addr
                )
                session['db_session_id'] = db_session_id
                print(f"   üîê Created database session: {db_session_id}")
            except Exception as e:
                logger.warning(f"Failed to create database session: {e}")
        
        print("")
    
    @app.route('/')
    def index():
        """Home page - What do you want to do?"""
        try:
            return render_template('home.html')
        except Exception as e:
            logger.error(f"Error rendering home page: {e}")
            try:
                return render_template('error.html', error_message="Failed to load home page"), 500
            except Exception as e2:
                logger.error(f"Error rendering error page: {e2}")
                return f"<h1>Application Error</h1><p>Failed to load home page: {e}</p><p>Template error: {e2}</p>", 500
    
    @app.route('/analyze')
    def analyze_page():
        """Analyze content page - text analysis and style checking."""
        try:
            return render_template('index.html')
        except Exception as e:
            logger.error(f"Error rendering analyze content page: {e}")
            try:
                return render_template('error.html', error_message="Failed to load analyze content page"), 500
            except Exception as e2:
                logger.error(f"Error rendering error page: {e2}")
                return f"<h1>Application Error</h1><p>Failed to load analyze content page: {e}</p><p>Template error: {e2}</p>", 500
    
    @app.route('/upload', methods=['POST'])
    @app.limiter.limit("10 per minute")  # Limit file uploads
    def upload_file():
        """Handle file upload and text extraction."""
        try:
            logger.info(f"üîç [ROUTE-DEBUG] /upload endpoint called")
            logger.info(f"üîç [ROUTE-DEBUG] request.files keys: {list(request.files.keys())}")
            
            if 'file' not in request.files:
                logger.error(f"‚ùå [ROUTE-DEBUG] No 'file' in request.files")
                return jsonify({'error': 'No file selected'}), 400
            
            file = request.files['file']
            logger.info(f"üîç [ROUTE-DEBUG] File object: {file}")
            logger.info(f"üîç [ROUTE-DEBUG] File filename: {file.filename}")
            
            if file.filename == '' or file.filename is None:
                logger.error(f"‚ùå [ROUTE-DEBUG] Empty filename")
                return jsonify({'error': 'No file selected'}), 400
            
            if file and document_processor.allowed_file(file.filename):
                filename = secure_filename(file.filename)
                logger.info(f"‚úÖ [ROUTE-DEBUG] Secure filename: {filename}")
                
                # Detect format from file extension
                detected_format = document_processor.detect_format_from_filename(filename)
                logger.info(f"‚úÖ [ROUTE-DEBUG] Detected format: {detected_format}")
                
                # Get file size (seek to end, get position, seek back to start)
                file.seek(0, os.SEEK_END)
                file_size = file.tell()
                file.seek(0)  # Reset to beginning for extraction
                logger.info(f"üîç [ROUTE-DEBUG] File size: {file_size} bytes")
                
                # Extract text without saving to disk (more secure)
                logger.info(f"üîç [ROUTE-DEBUG] Starting text extraction...")
                content = document_processor.extract_text_from_upload(file)
                
                if content:
                    logger.info(f"‚úÖ [ROUTE-DEBUG] Content extracted successfully: {len(content)} chars")
                    
                    # Get file extension
                    file_ext = filename.split('.')[-1].lower() if '.' in filename else 'unknown'
                    
                    result = {
                        'success': True,
                        'content': content,
                        'filename': filename,
                        'file_size': file_size,
                        'file_extension': file_ext,
                        'detected_format': detected_format,
                        'word_count': len(content.split()),
                        'char_count': len(content),
                        'message': 'File uploaded successfully. Please select content type and click Analyze.'
                    }
                    
                    logger.info(f"üì§ [ROUTE-DEBUG] Upload successful: {filename} ({file_size} bytes, format: {detected_format})")
                    logger.info(f"üîç [ROUTE-DEBUG] Returning result with keys: {list(result.keys())}")
                    
                    return jsonify(result)
                else:
                    logger.error(f"‚ùå [ROUTE-DEBUG] Content extraction returned None/empty")
                    return jsonify({'error': 'Failed to extract text from file'}), 400
            else:
                logger.error(f"‚ùå [ROUTE-DEBUG] File type not allowed: {file.filename}")
                return jsonify({'error': 'File type not supported'}), 400
                
        except RequestEntityTooLarge:
            logger.error(f"‚ùå [ROUTE-DEBUG] File too large")
            return jsonify({'error': 'File too large. Maximum size is 16MB.'}), 413
        except Exception as e:
            logger.error(f"‚ùå [ROUTE-DEBUG] Upload error: {str(e)}")
            import traceback
            logger.error(f"‚ùå [ROUTE-DEBUG] Traceback: {traceback.format_exc()}")
            return jsonify({'error': f'Upload failed: {str(e)}'}), 500
    
    @app.route('/analyze', methods=['POST'])
    @app.limiter.limit("5 per minute")  # Strict limit for heavy analysis endpoint
    def analyze_content():
        """Analyze text content for style issues with confidence data and real-time progress."""
        start_time = time.time()  # Track processing time
        try:
            data = request.get_json()
            content = data.get('content', '')
            format_hint = data.get('format_hint', 'auto')
            content_type = data.get('content_type', 'concept')  # NEW: Add content type
            session_id = data.get('session_id', '') if data else ''
            
            # Database integration: Get document and analysis IDs from request or create new ones
            document_id = data.get('document_id') if data else None
            analysis_id = data.get('analysis_id') if data else None
            db_session_id = session.get('db_session_id')
        
            # Enhanced: Support confidence threshold parameter
            confidence_threshold = data.get('confidence_threshold', None)
            include_confidence_details = data.get('include_confidence_details', True)
            
            if not content:
                return jsonify({'error': 'No content provided'}), 400
            
            # Validate content_type
            valid_content_types = ['concept', 'procedure', 'reference', 'assembly']
            if content_type not in valid_content_types:
                return jsonify({'error': f'Invalid content_type. Must be one of: {valid_content_types}'}), 400
                
            # If no session_id provided, generate one for this request
            if not session_id or not session_id.strip():
                import uuid
                session_id = str(uuid.uuid4())
            
            # Database integration: Create document and analysis if not provided
            if database_service and db_session_id and not (document_id and analysis_id):
                try:
                    document_id, analysis_id = database_service.process_document_upload(
                        session_id=db_session_id,
                        content=content,
                        filename="direct_input.txt",
                        document_format=format_hint,
                        content_type=content_type
                    )
                    logger.info(f"üìÑ Created database document: {document_id}, analysis: {analysis_id}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to create database document: {e}")
            
            # Start analysis in database
            if database_service and analysis_id:
                try:
                    database_service.start_analysis(analysis_id, analysis_mode="comprehensive", format_hint=format_hint)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to update analysis status: {e}")
            
            # Start analysis with progress updates
            logger.info(f"üîç [ANALYZE-DEBUG] Starting analysis for session {session_id}")
            logger.info(f"üîç [ANALYZE-DEBUG] content_type={content_type}")
            logger.info(f"üîç [ANALYZE-DEBUG] format_hint={format_hint}")
            logger.info(f"üîç [ANALYZE-DEBUG] confidence_threshold={confidence_threshold}")
            logger.info(f"üîç [ANALYZE-DEBUG] Content length: {len(content)} chars")
            logger.info(f"üîç [ANALYZE-DEBUG] Content preview (first 300 chars): {content[:300]}")
            
            emit_progress(session_id, 'analysis_start', 'Initializing analysis...', 'Setting up analysis pipeline', 10)
            
            # Enhanced: Configure analyzer with confidence threshold if provided
            if confidence_threshold is not None:
                logger.info(f"üîç [ANALYZE-DEBUG] Setting confidence threshold to {confidence_threshold}")
                # Temporarily adjust the confidence threshold for this request
                original_threshold = style_analyzer.structural_analyzer.confidence_threshold
                style_analyzer.structural_analyzer.confidence_threshold = confidence_threshold
                style_analyzer.structural_analyzer.rules_registry.set_confidence_threshold(confidence_threshold)
            
            # Analyze with structural blocks AND modular compliance
            logger.info(f"üîç [ANALYZE-DEBUG] Calling analyze_with_blocks...")
            logger.info(f"üîç [ANALYZE-DEBUG] Parameters: format_hint='{format_hint}', content_type='{content_type}'")
            
            emit_progress(session_id, 'structural_parsing', 'Parsing document structure...', 'Extracting content blocks and hierarchy', 25)
            
            analysis_result = style_analyzer.analyze_with_blocks(content, format_hint, content_type=content_type)
            
            emit_progress(session_id, 'style_analysis', 'Style analysis complete', 'Processed all grammar and style rules', 60)
            
            logger.info(f"‚úÖ [ANALYZE-DEBUG] analyze_with_blocks completed")
            logger.info(f"üîç [ANALYZE-DEBUG] Result keys: {list(analysis_result.keys())}")
            
            analysis = analysis_result.get('analysis', {})
            structural_blocks = analysis_result.get('structural_blocks', [])
            
            logger.info(f"üîç [ANALYZE-DEBUG] Extracted {len(structural_blocks)} structural blocks")
            if structural_blocks:
                logger.info(f"üîç [ANALYZE-DEBUG] First 3 block types: {[b.get('block_type') for b in structural_blocks[:3]]}")
            else:
                logger.warning(f"‚ö†Ô∏è [ANALYZE-DEBUG] No structural blocks found!")
            
            # Emit compliance check progress (always emit, regardless of result)
            emit_progress(session_id, 'compliance_check', 'Validating compliance', f'Checking {content_type} module requirements', 70)
            
            # Check if modular compliance was included in results
            if 'modular_compliance' in analysis_result:
                analysis['modular_compliance'] = analysis_result['modular_compliance']
            
            # Enhanced: Restore original threshold if it was modified
            if confidence_threshold is not None:
                style_analyzer.structural_analyzer.confidence_threshold = original_threshold
                style_analyzer.structural_analyzer.rules_registry.set_confidence_threshold(original_threshold)
            
            # üÜï NEW: Process metadata generation (Module 3)
            metadata_result = None
            try:
                # Import metadata assistant
                from metadata_assistant import MetadataAssistant
                
                # Initialize metadata assistant with progress callback
                # REMAP metadata progress from 0-100% to 85-95% range
                def metadata_progress_callback(session_id, stage, message, details, progress):
                    # Remap internal progress (0-100) to overall progress (85-95)
                    remapped_progress = 85 + (progress / 100) * 10  # 0‚Üí85, 100‚Üí95
                    emit_progress(session_id, stage, message, details, int(remapped_progress))
                
                # Import and create ModelManager directly
                from models import ModelManager
                model_manager = ModelManager()
                
                metadata_assistant = MetadataAssistant(
                    model_manager=model_manager,
                    progress_callback=metadata_progress_callback
                )
                
                # Don't emit here - metadata assistant will emit starting at 85% via callback
                
                # Get spaCy document from analysis if available
                spacy_doc = None
                if hasattr(style_analyzer, 'nlp') and style_analyzer.nlp:
                    try:
                        # Reuse parsed spaCy doc to avoid re-processing
                        spacy_doc = style_analyzer.nlp(content[:10000])  # Limit for performance
                    except Exception as e:
                        logger.debug(f"Could not reuse spaCy parsing: {e}")
                
                # Generate metadata using existing analysis artifacts
                metadata_result = metadata_assistant.generate_metadata(
                    content=content,
                    spacy_doc=spacy_doc,
                    structural_blocks=structural_blocks,
                    analysis_result=analysis,
                    session_id=session_id,
                    content_type=content_type
                )
                
                if metadata_result and metadata_result.get('success'):
                    # Don't emit here - metadata assistant already emitted 100% (remapped to 95%)
                    pass
                else:
                    logger.warning("Metadata generation failed or returned no results")
                    # If metadata failed, manually set to 95% to continue
                    emit_progress(session_id, 'metadata_skipped', 'Metadata skipped', 'Continuing without metadata', 95)
                
            except Exception as e:
                logger.warning(f"Metadata generation failed: {e}")
                # Continue without metadata - graceful degradation
                metadata_result = None

            # Calculate processing time (moved before emit to include accurate time)
            processing_time = time.time() - start_time
            analysis['processing_time'] = processing_time
            analysis['content_type'] = content_type  # Include content type in results
            
            # Database integration: Store analysis results
            if database_service and analysis_id and document_id:
                try:
                    # Convert errors to database format
                    violations = []
                    errors = analysis.get('errors', [])
                    for error in errors:
                        violations.append({
                            'rule_id': error.get('type', 'unknown'),
                            'error_text': error.get('text', ''),
                            'error_message': error.get('message', ''),
                            'error_position': error.get('start', 0),
                            'end_position': error.get('end'),
                            'line_number': error.get('line'),
                            'column_number': error.get('column'),
                            'severity': error.get('severity', 'medium'),
                            'confidence_score': error.get('confidence', 0.5),
                            'suggestion': error.get('suggestion'),
                            'context_before': error.get('context_before'),
                            'context_after': error.get('context_after'),
                            'metadata': error.get('metadata', {})
                        })
                    
                    # Store results in database
                    database_service.store_analysis_results(
                        analysis_id=analysis_id,
                        document_id=document_id,
                        violations=violations,
                        processing_time=processing_time,
                        total_blocks_analyzed=len(structural_blocks)
                    )
                    
                    logger.info(f"üìä Stored {len(violations)} violations in database")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to store analysis results: {e}")
            
            logger.info(f"Analysis completed in {processing_time:.2f}s for session {session_id}")
            
            # Enhanced: Prepare confidence metadata
            confidence_metadata = {
                'confidence_threshold_used': confidence_threshold or analysis.get('confidence_threshold', 0.43),
                'enhanced_validation_enabled': analysis.get('enhanced_validation_enabled', False),
                'confidence_filtering_applied': confidence_threshold is not None,
                'content_type': content_type  # Include content type in metadata
            }
            
            # Enhanced: Add validation performance if available
            if analysis.get('validation_performance'):
                confidence_metadata['validation_performance'] = analysis.get('validation_performance')
            
            # Enhanced: Add enhanced error statistics if available
            if analysis.get('enhanced_error_stats'):
                confidence_metadata['enhanced_error_stats'] = analysis.get('enhanced_error_stats')
            
            # Return enhanced results with modular compliance data, metadata, and database IDs
            response_data = {
                'success': True,
                'analysis': analysis,
                'processing_time': processing_time,
                'session_id': session_id,
                'content_type': content_type,  # Include content type in response
                'confidence_metadata': confidence_metadata,
                'metadata_assistant': metadata_result,  # üÜï Module 3: Metadata generation results
                'api_version': '2.0'  # Indicate enhanced API version
            }
            
            # Include database IDs if available
            if database_service and db_session_id:
                response_data.update({
                    'db_session_id': db_session_id,
                    'document_id': document_id,
                    'analysis_id': analysis_id
                })
            
            # Include detailed confidence information if requested
            if include_confidence_details:
                response_data['confidence_details'] = {
                    'confidence_system_available': True,
                    'threshold_range': {'min': 0.0, 'max': 1.0, 'default': 0.43},
                    'confidence_levels': {
                        'HIGH': {'threshold': 0.7, 'description': 'High confidence errors - very likely to be correct'},
                        'MEDIUM': {'threshold': 0.5, 'description': 'Medium confidence errors - likely to be correct'},
                        'LOW': {'threshold': 0.0, 'description': 'Low confidence errors - may need review'}
                    }
                }
            
            # Include structural blocks if available
            if structural_blocks:
                response_data['structural_blocks'] = structural_blocks
                
            # Enhanced: Add backward compatibility flag
            response_data['backward_compatible'] = True
            
            # Emit progress completion AFTER response is fully prepared (moved from line 308)
            emit_progress(session_id, 'analysis_complete', 'Analysis complete!', f'Analysis completed in {processing_time:.2f}s', 100)
            
            emit_completion(session_id, True, response_data)
            
            return jsonify(response_data)
            
        except Exception as e:
            logger.error(f"Analysis error for session {session_id}: {str(e)}")
            error_response = {
                'success': False,
                'error': f'Analysis failed: {str(e)}',
                'session_id': session_id
            }
            emit_completion(session_id, False, error_response)
            return jsonify(error_response), 500
    
    @app.route('/generate-pdf-report', methods=['POST'])
    def generate_pdf_report():
        """Generate a comprehensive PDF report of the writing analysis."""
        try:
            data = request.get_json()
            
            # Extract required data
            analysis_data = data.get('analysis', {})
            content = data.get('content', '')
            structural_blocks = data.get('structural_blocks', [])
            
            if not analysis_data:
                return jsonify({'error': 'No analysis data provided'}), 400
            
            if not content:
                return jsonify({'error': 'No content provided'}), 400
            
            # Import PDF generator (lazy import to avoid startup delays)
            try:
                from .pdf_report_generator import PDFReportGenerator
            except ImportError as e:
                logger.error(f"Failed to import PDF generator: {e}")
                return jsonify({'error': 'PDF generation not available - missing dependencies'}), 500
            
            # Generate PDF report
            logger.info("Generating PDF report...")
            pdf_generator = PDFReportGenerator()
            
            pdf_bytes = pdf_generator.generate_report(
                analysis_data=analysis_data,
                content=content,
                structural_blocks=structural_blocks if structural_blocks else None
            )
            
            # Create filename with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"writing_analytics_report_{timestamp}.pdf"
            
            # Return PDF as downloadable file
            pdf_buffer = BytesIO(pdf_bytes)
            pdf_buffer.seek(0)
            
            logger.info(f"PDF report generated successfully ({len(pdf_bytes)} bytes)")
            
            return send_file(
                pdf_buffer,
                as_attachment=True,
                download_name=filename,
                mimetype='application/pdf'
            )
            
        except Exception as e:
            logger.error(f"PDF generation error: {str(e)}")
            return jsonify({'error': f'PDF generation failed: {str(e)}'}), 500
    
    @app.route('/rewrite-block', methods=['POST'])
    def rewrite_block():
        """AI-powered single block rewriting."""
        start_time = time.time()
        try:
            data = request.get_json()
            block_content = data.get('block_content', '')
            block_errors = data.get('block_errors', [])
            block_type = data.get('block_type', 'paragraph')
            block_id = data.get('block_id', '')
            session_id = data.get('session_id', '')
            
            print(f"\nüîç DEBUG API ROUTE: /rewrite-block")
            print(f"   üìã Block ID: {block_id}")
            print(f"   üìã Session ID: {session_id}")
            print(f"   üìã Block Type: {block_type}")
            print(f"   üìã Content Length: {len(block_content)}")
            print(f"   üìã Errors Count: {len(block_errors)}")
            print(f"   üìã Content Preview: {repr(block_content[:100])}")
            
            # Validate required inputs
            if not block_content or not block_content.strip():
                print(f"   ‚ùå No block content provided")
                return jsonify({'error': 'No block content provided'}), 400
            
            if not block_id:
                print(f"   ‚ùå Block ID is required")
                return jsonify({'error': 'Block ID is required'}), 400
            
            if not block_errors:
                print(f"   ‚ö†Ô∏è  No errors provided - returning original content")
            
            logger.info(f"Starting block rewrite for session {session_id}, block {block_id}, type: {block_type}")
            
            # Emit progress start via WebSocket
            print(f"   üì° Emitting initial progress update...")
            if session_id:
                emit_progress(session_id, 'block_processing_start', 
                            f'Starting rewrite for {block_type}', 
                            f'Processing block {block_id}', 0)
                print(f"   ‚úÖ Initial progress update emitted to session: {session_id}")
            else:
                # If no session_id provided, broadcast to all connected clients
                emit_progress('', 'block_processing_start', 
                            f'Starting rewrite for {block_type}', 
                            f'Processing block {block_id}', 0)
                print(f"   ‚úÖ Initial progress update broadcasted to all sessions")
            
            # Debug: Check ai_rewriter structure
            print(f"   üîç DEBUG AI Rewriter Structure:")
            print(f"      ai_rewriter type: {type(ai_rewriter)}")
            print(f"      hasattr(ai_rewriter, 'ai_rewriter'): {hasattr(ai_rewriter, 'ai_rewriter')}")
            if hasattr(ai_rewriter, 'ai_rewriter'):
                print(f"      ai_rewriter.ai_rewriter type: {type(ai_rewriter.ai_rewriter)}")
                print(f"      hasattr(ai_rewriter.ai_rewriter, 'assembly_line'): {hasattr(ai_rewriter.ai_rewriter, 'assembly_line')}")
                if hasattr(ai_rewriter.ai_rewriter, 'assembly_line'):
                    print(f"      assembly_line type: {type(ai_rewriter.ai_rewriter.assembly_line)}")
                    print(f"      assembly_line progress_callback: {getattr(ai_rewriter.ai_rewriter.assembly_line, 'progress_callback', 'NOT_FOUND')}")
            print(f"      hasattr(ai_rewriter, 'assembly_line'): {hasattr(ai_rewriter, 'assembly_line')}")
            
            # Process single block through assembly line
            if hasattr(ai_rewriter, 'ai_rewriter') and hasattr(ai_rewriter.ai_rewriter, 'assembly_line'):
                print(f"   üè≠ Using DocumentRewriter -> AIRewriter -> AssemblyLine path")
                # Full DocumentRewriter with assembly line support - PASS session_id and block_id for live updates
                result = ai_rewriter.ai_rewriter.assembly_line.apply_block_level_assembly_line_fixes(
                    block_content, block_errors, block_type, session_id=session_id, block_id=block_id
                )
                print(f"   ‚úÖ Assembly line processing completed")
            elif hasattr(ai_rewriter, 'assembly_line'):
                print(f"   üè≠ Using Direct AIRewriter -> AssemblyLine path")
                # Direct AIRewriter with assembly line support - PASS session_id and block_id for live updates
                result = ai_rewriter.assembly_line.apply_block_level_assembly_line_fixes(
                    block_content, block_errors, block_type, session_id=session_id, block_id=block_id
                )
                print(f"   ‚úÖ Assembly line processing completed")
            else:
                print(f"   ‚ö†Ô∏è  Using fallback SimpleAIRewriter path")
                # Fallback SimpleAIRewriter - use basic rewrite method
                result = ai_rewriter.rewrite(block_content, block_errors, block_type)
                # Add missing fields for consistency
                result.update({
                    'applicable_stations': ['fallback'],
                    'block_type': block_type,
                    'assembly_line_used': False
                })
                print(f"   ‚úÖ Fallback processing completed")
            
            # Add request metadata
            processing_time = time.time() - start_time
            result.update({
                'block_id': block_id,
                'session_id': session_id,
                'processing_time': processing_time,
                'success': 'error' not in result
            })
            
            # Emit completion via WebSocket
            if session_id:
                emit_completion(session_id, 'block_processing_complete', result)
            
            logger.info(f"Block rewrite completed in {processing_time:.2f}s - {result.get('errors_fixed', 0)} errors fixed")
            return jsonify(result)
            
        except Exception as e:
            logger.error(f"Block rewrite error: {str(e)}")
            error_result = {
                'error': f'Block rewrite failed: {str(e)}',
                'success': False,
                'block_id': data.get('block_id', '') if 'data' in locals() else '',
                'session_id': data.get('session_id', '') if 'data' in locals() else ''
            }
            return jsonify(error_result), 500


    
    @app.route('/refine', methods=['POST'])
    def refine_content():
        """AI-powered content refinement (Pass 2)."""
        start_time = time.time()
        try:
            data = request.get_json()
            first_pass_result = data.get('first_pass_result', '')
            original_errors = data.get('original_errors', [])
            session_id = data.get('session_id', '')
            
            if not first_pass_result:
                return jsonify({'error': 'No first pass result provided'}), 400
            
            logger.info(f"Starting refinement for session {session_id}")
            
            result = ai_rewriter.refine_content(first_pass_result, original_errors)
            
            processing_time = time.time() - start_time
            result['processing_time'] = processing_time
            
            logger.info(f"Refinement completed in {processing_time:.2f}s")
            return jsonify(result)
            
        except Exception as e:
            logger.error(f"Refinement error: {str(e)}")
            return jsonify({'error': f'Refinement failed: {str(e)}'}), 500
    
    @app.route('/create-content')
    def create_content():
        """Content creation page with form-driven UI."""
        try:
            return render_template('create_content.html')
        except Exception as e:
            logger.error(f"Error rendering content creation page: {e}")
            try:
                return render_template('error.html', error_message="Failed to load content creation page"), 500
            except Exception as e2:
                logger.error(f"Error rendering error page: {e2}")
                return f"<h1>Application Error</h1><p>Failed to load content creation page: {e}</p><p>Template error: {e2}</p>", 500
    
    @app.route('/api/feedback', methods=['POST'])
    def submit_feedback():
        """Submit user feedback on error accuracy with database storage."""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'No JSON data provided'}), 400
            
            # Validate required fields (handle both error_id and violation_id)
            required_fields = ['error_type', 'error_message', 'feedback_type']
            for field in required_fields:
                if field not in data:
                    return jsonify({'error': f'Missing required field: {field}'}), 400
            
            # Handle both error_id (from frontend) and violation_id (database field)
            violation_id = data.get('violation_id') or data.get('error_id')
            if not violation_id:
                return jsonify({'error': 'Missing required field: violation_id or error_id'}), 400
            
            # Extract request metadata
            user_agent = request.headers.get('User-Agent')
            ip_address = request.remote_addr
            db_session_id = session.get('db_session_id')
            
            # Database storage with file-based fallback
            if not database_service:
                # Fallback to file-based storage (for production without database)
                logger.warning("Database service unavailable - using file-based feedback storage")
                
                from app_modules.feedback_storage import FeedbackStorage
                # Use environment variable for storage path, fallback to PVC mount point
                feedback_storage_dir = os.environ.get('FEEDBACK_STORAGE_DIR', '/opt/app-root/src/feedback_data')
                file_storage = FeedbackStorage(storage_dir=feedback_storage_dir)
                
                success, message, feedback_id = file_storage.store_feedback(
                    feedback_data={
                        'session_id': data.get('session_id', 'unknown'),
                        'error_id': violation_id,
                        'error_type': data['error_type'],
                        'error_message': data['error_message'],
                        'error_text': data.get('error_text', ''),
                        'context_before': data.get('context_before'),
                        'context_after': data.get('context_after'),
                        'feedback_type': data['feedback_type'],
                        'confidence_score': data.get('confidence_score', 0.5),
                        'user_reason': data.get('user_reason')
                    },
                    user_agent=user_agent,
                    ip_address=ip_address
                )
                
                if success:
                    response_data = {
                        'success': True,
                        'message': 'Feedback stored to file (database unavailable)',
                        'feedback_id': feedback_id,
                        'violation_id': violation_id,
                        'timestamp': datetime.now().isoformat(),
                        'storage_type': 'file_fallback'
                    }
                    logger.info(f"üìÅ File-based feedback stored: {feedback_id}")
                    return jsonify(response_data), 201
                else:
                    logger.error(f"‚ùå File-based feedback storage failed: {message}")
                    return jsonify({'error': f'Feedback storage failed: {message}'}), 500
                
            # Ensure we have a database session ID
            if not db_session_id:
                # Create a new database session if missing
                try:
                    db_session_id = database_service.create_user_session(user_agent=user_agent, ip_address=ip_address)
                    session['db_session_id'] = db_session_id
                    logger.info(f"‚úÖ Created new database session: {db_session_id}")
                except Exception as e:
                    logger.error(f"‚ùå Failed to create database session: {e}")
                    return jsonify({'error': 'Failed to create database session'}), 500
            
            try:
                success, feedback_id = database_service.store_user_feedback(
                    session_id=db_session_id,
                    violation_id=violation_id,
                    feedback_data={
                        'error_type': data['error_type'],
                        'error_message': data['error_message'],
                        'feedback_type': data['feedback_type'],
                        'confidence_score': data.get('confidence_score', 0.5),
                        'user_reason': data.get('user_reason')
                    },
                    user_agent=user_agent,
                    ip_address=ip_address
                )
                
                if success:
                    response_data = {
                        'success': True,
                        'message': 'Feedback stored successfully in PostgreSQL',
                        'feedback_id': feedback_id,
                        'violation_id': violation_id,  # Include violation_id for frontend tracking
                        'timestamp': datetime.now().isoformat(),
                        'storage_type': 'postgresql'
                    }
                    
                    logger.info(f"üêò PostgreSQL feedback submitted: {feedback_id}")
                    return jsonify(response_data), 201
                else:
                    logger.error(f"‚ùå PostgreSQL feedback storage failed: {feedback_id}")
                    return jsonify({'error': 'Failed to store feedback in PostgreSQL'}), 500
                    
            except Exception as e:
                logger.error(f"‚ùå PostgreSQL feedback error: {e}")
                return jsonify({'error': f'PostgreSQL storage failed: {str(e)}'}), 500
                
        except Exception as e:
            logger.error(f"Feedback submission error: {str(e)}")
            return jsonify({'error': f'Feedback submission failed: {str(e)}'}), 500
    
    @app.route('/api/feedback/stats', methods=['GET'])
    def get_feedback_stats():
        """Get feedback statistics from PostgreSQL."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service unavailable'}), 503
            
            # Get query parameters
            session_id = request.args.get('session_id')
            days_back = request.args.get('days_back', default=7, type=int)
            
            # Validate days_back parameter
            if days_back < 1 or days_back > 365:
                return jsonify({'error': 'days_back must be between 1 and 365'}), 400
            
            # Get statistics from PostgreSQL
            stats = database_service.get_feedback_statistics(session_id=session_id, days_back=days_back)
            
            response_data = {
                'success': True,
                'statistics': stats,
                'timestamp': datetime.now().isoformat(),
                'source': 'postgresql'
            }
            
            return jsonify(response_data)
            
        except Exception as e:
            logger.error(f"PostgreSQL feedback stats error: {str(e)}")
            return jsonify({'error': f'Failed to retrieve feedback stats: {str(e)}'}), 500
    
    @app.route('/api/feedback/insights', methods=['GET'])
    def get_feedback_insights():
        """Get aggregated feedback insights and analytics."""
        try:
            from .feedback_storage import feedback_storage
            
            # Get query parameters
            days_back = request.args.get('days_back', default=30, type=int)
            
            # Validate days_back parameter
            if days_back < 1 or days_back > 365:
                return jsonify({'error': 'days_back must be between 1 and 365'}), 400
            
            # Get insights
            insights = feedback_storage.aggregate_feedback_insights(days_back=days_back)
            
            response_data = {
                'success': True,
                'insights': insights,
                'timestamp': datetime.now().isoformat(),
                'api_version': '2.0'
            }
            
            return jsonify(response_data)
            
        except Exception as e:
            logger.error(f"Feedback insights error: {str(e)}")
            return jsonify({'error': f'Failed to retrieve feedback insights: {str(e)}'}), 500
    
    # Database-powered analytics endpoints
    @app.route('/api/analytics/session', methods=['GET'])
    def get_session_analytics():
        """Get analytics for current user session."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service not available'}), 503
            
            db_session_id = session.get('db_session_id')
            if not db_session_id:
                return jsonify({'error': 'No database session found'}), 400
            
            analytics = database_service.get_session_analytics(db_session_id)
            return jsonify(analytics)
            
        except Exception as e:
            logger.error(f"Session analytics error: {str(e)}")
            return jsonify({'error': f'Failed to retrieve analytics: {str(e)}'}), 500
    
    @app.route('/api/analytics/rules', methods=['GET'])
    def get_rule_analytics():
        """Get rule performance analytics."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service not available'}), 503
            
            rule_id = request.args.get('rule_id')
            days_back = request.args.get('days_back', default=30, type=int)
            
            if rule_id:
                performance = database_service.get_rule_performance(rule_id, days_back)
            else:
                performance = database_service.get_rule_performance(days_back=days_back)
            
            return jsonify(performance)
            
        except Exception as e:
            logger.error(f"Rule analytics error: {str(e)}")
            return jsonify({'error': f'Failed to retrieve rule analytics: {str(e)}'}), 500
    
    @app.route('/api/analytics/model-usage', methods=['GET'])
    def get_model_usage_analytics():
        """Get AI model usage statistics."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service not available'}), 503
            
            db_session_id = session.get('db_session_id')
            operation_type = request.args.get('operation_type')
            days_back = request.args.get('days_back', default=30, type=int)
            
            stats = database_service.get_model_usage_stats(
                session_id=db_session_id,
                operation_type=operation_type,
                days_back=days_back
            )
            
            return jsonify(stats)
            
        except Exception as e:
            logger.error(f"Model usage analytics error: {str(e)}")
            return jsonify({'error': f'Failed to retrieve model usage: {str(e)}'}), 500
    
    @app.route('/health')
    @app.limiter.exempt  # Exempt from rate limiting to prevent pod restarts
    def health_check():
        """Simple health check endpoint for Kubernetes/OpenShift probes."""
        # Simple check - just return OK if the app is running
        return jsonify({'status': 'ok'}), 200
    
    @app.route('/health/detailed')
    @app.limiter.exempt  # Exempt from rate limiting
    def health_check_detailed():
        """Detailed health check endpoint with database status."""
        try:
            health_status = {
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'services': {
                    'document_processor': document_processor is not None,
                    'style_analyzer': style_analyzer is not None,
                    'ai_rewriter': ai_rewriter is not None,
                    'feedback_storage': True,  # File-based fallback always available
                    'database': database_service is not None
                }
            }
            
            # Add database health check
            if database_service:
                try:
                    db_health = database_service.get_system_health()
                    health_status['database_health'] = db_health
                except Exception as e:
                    health_status['database_health'] = {'status': 'unhealthy', 'error': str(e)}
                    health_status['status'] = 'degraded'
            
            return jsonify(health_status)
            
        except Exception as e:
            logger.error(f"Health check error: {str(e)}")
            return jsonify({
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }), 500
    
    @app.route('/health/nltk-diagnostic')
    @app.limiter.exempt  # Exempt from rate limiting
    def nltk_diagnostic():
        """Diagnostic endpoint to test NLTK and textstat configuration."""
        import nltk
        import textstat
        
        results = {
            'nltk_data_paths': nltk.data.path[:3],  # Show first 3 paths
            'nltk_data_env': os.getenv('NLTK_DATA', 'NOT_SET'),
            'tests': {}
        }
        
        # Test 1: Check if NLTK data resources exist
        test_resources = ['punkt', 'stopwords', 'cmudict']
        for resource in test_resources:
            try:
                if resource == 'punkt':
                    nltk.data.find('tokenizers/punkt')
                else:
                    nltk.data.find(f'corpora/{resource}')
                results['tests'][f'nltk_{resource}'] = '‚úÖ Found'
            except LookupError as e:
                results['tests'][f'nltk_{resource}'] = f'‚ùå Missing: {str(e)[:100]}'
        
        # Test 2: Test textstat on sample text
        sample_text = "This is a simple test sentence. It should produce valid readability scores."
        try:
            flesch = textstat.flesch_reading_ease(sample_text)
            results['tests']['textstat_flesch'] = f'‚úÖ {flesch:.1f}'
        except Exception as e:
            results['tests']['textstat_flesch'] = f'‚ùå Error: {str(e)[:200]}'
        
        try:
            smog = textstat.smog_index(sample_text)
            results['tests']['textstat_smog'] = f'‚úÖ {smog:.1f}'
        except Exception as e:
            results['tests']['textstat_smog'] = f'‚ùå Error: {str(e)[:200]}'
        
        try:
            grade = textstat.flesch_kincaid_grade(sample_text)
            results['tests']['textstat_grade'] = f'‚úÖ {grade:.1f}'
        except Exception as e:
            results['tests']['textstat_grade'] = f'‚ùå Error: {str(e)[:200]}'
        
        # Overall status
        all_passed = all('‚úÖ' in str(v) for v in results['tests'].values())
        results['status'] = 'PASS' if all_passed else 'FAIL'
        
        return jsonify(results), 200 if all_passed else 500
    
    @app.route('/api/feedback/existing', methods=['GET'])
    def get_existing_feedback():
        """Get existing feedback for a specific session and violation."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service unavailable'}), 503
                
            session_id = request.args.get('session_id')
            violation_id = request.args.get('violation_id')
            
            if not session_id or not violation_id:
                return jsonify({'error': 'Missing required parameters: session_id and violation_id'}), 400
            
            success, feedback_data = database_service.get_existing_feedback(session_id, violation_id)
            
            if success:
                if feedback_data:
                    return jsonify({
                        'success': True,
                        'feedback': feedback_data
                    }), 200
                else:
                    return jsonify({
                        'success': True,
                        'feedback': None,
                        'message': 'No existing feedback found'
                    }), 200
            else:
                return jsonify({'error': 'Failed to retrieve existing feedback'}), 500
                
        except Exception as e:
            logger.error(f"Get existing feedback error: {str(e)}")
            return jsonify({'error': f'Failed to get existing feedback: {str(e)}'}), 500
    
    @app.route('/api/feedback/session', methods=['GET'])
    def get_session_feedback():
        """Get all feedback for the current session."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service unavailable'}), 503
                
            db_session_id = session.get('db_session_id')
            if not db_session_id:
                return jsonify({
                    'success': True,
                    'feedback': [],
                    'message': 'No active session'
                }), 200
            
            feedback_list = database_service.feedback_dao.get_session_feedback(db_session_id)
            
            # Convert feedback to dict format
            feedback_data = []
            for feedback in feedback_list:
                violation = feedback.violation if hasattr(feedback, 'violation') else None
                
                feedback_data.append({
                    'feedback_id': feedback.feedback_id,
                    'violation_id': feedback.violation_id,
                    'error_type': feedback.error_type,
                    'error_message': feedback.error_message,
                    'error_text': violation.error_text if violation else '',
                    'context_before': violation.context_before if violation else None,
                    'context_after': violation.context_after if violation else None,
                    'feedback_type': feedback.feedback_type.value,
                    'confidence_score': feedback.confidence_score,
                    'user_reason': feedback.user_reason,
                    'timestamp': feedback.timestamp.isoformat()
                })
            
            return jsonify({
                'success': True,
                'feedback': feedback_data,
                'session_id': db_session_id
            }), 200
                
        except Exception as e:
            logger.error(f"Get session feedback error: {str(e)}")
            return jsonify({'error': f'Failed to get session feedback: {str(e)}'}), 500
    
    @app.route('/api/feedback', methods=['DELETE'])
    def delete_feedback():
        """Delete user feedback for a specific violation."""
        try:
            if not database_service:
                return jsonify({'error': 'Database service unavailable'}), 503
                
            data = request.get_json()
            if not data:
                return jsonify({'error': 'No JSON data provided'}), 400
            
            # Handle both violation_id (from database) and error_id (frontend generated)
            violation_id = data.get('violation_id')
            error_id = data.get('error_id')
            feedback_id = data.get('feedback_id')  # Direct feedback ID if available
            
            db_session_id = session.get('db_session_id')
            if not db_session_id:
                return jsonify({'error': 'No active session'}), 400
            
            logger.info(f"[DELETE] Session: {db_session_id}, violation_id: {violation_id}, error_id: {error_id}, feedback_id: {feedback_id}")
            
            success = False
            message = "No feedback found to delete"
            
            # Try different approaches to find and delete the feedback
            if feedback_id:
                # Direct deletion by feedback_id
                logger.info(f"[DELETE] Attempting deletion by feedback_id: {feedback_id}")
                try:
                    feedback = database_service.feedback_dao.get_session_feedback(db_session_id)
                    target_feedback = None
                    for fb in feedback:
                        if fb.feedback_id == feedback_id:
                            target_feedback = fb
                            break
                    
                    if target_feedback:
                        success = database_service.feedback_dao.delete_feedback(db_session_id, target_feedback.violation_id)
                        message = "Feedback deleted successfully" if success else "Failed to delete feedback"
                except Exception as e:
                    logger.error(f"[DELETE] Error deleting by feedback_id: {e}")
            
            elif violation_id:
                # Deletion by violation_id
                logger.info(f"[DELETE] Attempting deletion by violation_id: {violation_id}")
                success, message = database_service.delete_user_feedback(db_session_id, violation_id)
            
            elif error_id:
                # Find by error_id (frontend generated ID) - need to match against all feedback for session
                logger.info(f"[DELETE] Attempting to find feedback by error_id: {error_id}")
                try:
                    all_feedback = database_service.feedback_dao.get_session_feedback(db_session_id)
                    for feedback in all_feedback:
                        # Try to reconstruct the error object and generate the same error_id
                        reconstructed_error = {
                            'type': feedback.error_type,
                            'message': feedback.error_message
                        }
                        
                        # This is a simplified check - in practice, you'd want to implement 
                        # the same generateErrorId logic or store the original error_id
                        if feedback.violation_id == error_id:  # Simple fallback
                            success = database_service.feedback_dao.delete_feedback(db_session_id, feedback.violation_id)
                            message = "Feedback deleted successfully" if success else "Failed to delete feedback"
                            break
                except Exception as e:
                    logger.error(f"[DELETE] Error finding feedback by error_id: {e}")
            
            if success:
                logger.info(f"[DELETE] Successfully deleted feedback for session: {db_session_id}")
                return jsonify({
                    'success': True,
                    'message': message
                }), 200
            else:
                logger.warning(f"[DELETE] No feedback found to delete: {message}")
                return jsonify({'error': message}), 404
                
        except Exception as e:
            logger.error(f"Delete feedback error: {str(e)}")
            return jsonify({'error': f'Failed to delete feedback: {str(e)}'}), 500
    
    # Metadata Assistant API Endpoints
    @app.route('/api/metadata/suggestions', methods=['POST'])
    def get_metadata_suggestions():
        """Get AI-powered metadata suggestions for interactive editing."""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'No JSON data provided'}), 400
            
            current_metadata = data.get('current_metadata', {})
            action = data.get('action')  # 'keyword_removed', 'tag_changed', etc.
            context = data.get('context', {})
            
            suggestions = []
            
            if action == 'keyword_removed':
                # Suggest alternative keywords based on content context
                removed_keyword = data.get('removed_keyword', '')
                suggestions = [
                    {'type': 'keyword', 'value': 'documentation', 'confidence': 0.8, 'reason': 'Common related term'},
                    {'type': 'keyword', 'value': 'guide', 'confidence': 0.7, 'reason': 'Content pattern match'}
                ]
                
            elif action == 'taxonomy_changed':
                # Suggest related category adjustments
                old_tag = data.get('old_tag', '')
                new_tag = data.get('new_tag', '')
                suggestions = [
                    {'type': 'taxonomy', 'value': 'Tutorial', 'confidence': 0.9, 'reason': f'Related to {new_tag}'},
                    {'type': 'taxonomy', 'value': 'Best_Practices', 'confidence': 0.6, 'reason': 'Complementary category'}
                ]
                
            elif action == 'request_general':
                # General suggestions based on content analysis
                suggestions = [
                    {'type': 'keyword', 'value': 'implementation', 'confidence': 0.85, 'reason': 'Content analysis'},
                    {'type': 'keyword', 'value': 'configuration', 'confidence': 0.75, 'reason': 'Technical pattern'},
                    {'type': 'taxonomy', 'value': 'Reference', 'confidence': 0.8, 'reason': 'Content structure'}
                ]
            
            return jsonify({
                'success': True,
                'suggestions': suggestions,
                'action': action,
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Metadata suggestions error: {str(e)}")
            return jsonify({'error': f'Failed to get suggestions: {str(e)}'}), 500
    
    @app.route('/api/metadata/record-interaction', methods=['POST'])
    def record_metadata_interaction():
        """Record metadata editing interactions for learning."""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'No JSON data provided'}), 400
            
            # Record the interaction (this would integrate with existing feedback system)
            interaction_type = data.get('type')  # 'edit', 'add', 'remove'
            component = data.get('component')    # 'keywords', 'taxonomy', 'title'
            old_value = data.get('old_value')
            new_value = data.get('new_value')
            
            # Log for now (in production, this would go to database)
            logger.info(f"Metadata interaction recorded: {interaction_type} {component} '{old_value}' ‚Üí '{new_value}'")
            
            return jsonify({
                'success': True,
                'message': 'Interaction recorded',
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Record metadata interaction error: {str(e)}")
            return jsonify({'error': f'Failed to record interaction: {str(e)}'}), 500
    
    # üÜï Performance Monitoring Dashboard Endpoints
    @app.route('/api/analytics/metadata-performance', methods=['GET'])
    def get_metadata_performance_metrics():
        """Get metadata assistant performance metrics for monitoring dashboard."""
        try:
            # Get metadata assistant instance (would need to be available in scope)
            # For now, we'll use a mock response structure
            
            # In production, this would integrate with MetadataAssistant.get_performance_metrics()
            metrics = {
                'total_requests': 150,
                'successful_requests': 142,
                'failed_requests': 8,
                'success_rate': 0.947,
                'cache_hits': 45,
                'cache_misses': 105,
                'cache_hit_rate': 0.3,
                'avg_processing_time': 2.3,
                'max_processing_time': 8.1,
                'min_processing_time': 0.8,
                'component_performance': {
                    'title_extraction': {'avg_time': 0.5, 'success_rate': 0.98},
                    'keyword_extraction': {'avg_time': 0.8, 'success_rate': 0.95},
                    'description_generation': {'avg_time': 1.2, 'success_rate': 0.92},
                    'taxonomy_classification': {'avg_time': 0.6, 'success_rate': 0.88}
                },
                'health_status': 'healthy',
                'last_updated': datetime.now().isoformat()
            }
            
            return jsonify({
                'success': True,
                'metrics': metrics,
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Performance metrics error: {str(e)}")
            return jsonify({'error': f'Failed to get performance metrics: {str(e)}'}), 500
    
    @app.route('/api/analytics/content-performance', methods=['GET'])
    def get_content_performance_analytics():
        """Get content performance analytics and SEO insights."""
        try:
            # Import analytics service
            from metadata_assistant.analytics import ContentPerformanceAnalytics
            
            # Initialize analytics service (would be dependency injected in production)
            analytics_service = ContentPerformanceAnalytics(database_session=None)
            
            # Use Flask-SQLAlchemy db session
            from database import db
            analytics_service.set_database_session(db.session)
            
            # Get time period from query parameters
            time_period_days = request.args.get('days', 30, type=int)
            
            # Generate analytics
            seo_analysis = analytics_service.generate_seo_opportunity_analysis(time_period_days)
            content_gaps = analytics_service.generate_content_gap_analysis()
            learning_insights = analytics_service.get_metadata_learning_insights()
            
            return jsonify({
                'success': True,
                'analytics': {
                    'seo_opportunities': seo_analysis,
                    'content_gaps': content_gaps,
                    'learning_insights': learning_insights
                },
                'analysis_period_days': time_period_days,
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Content performance analytics error: {str(e)}")
            return jsonify({'error': f'Failed to generate analytics: {str(e)}'}), 500
    
    @app.route('/api/analytics/metadata-health', methods=['GET'])
    def get_metadata_health_status():
        """Get health status and system diagnostics for metadata assistant."""
        try:
            # System health checks
            health_status = {
                'overall_status': 'healthy',
                'components': {
                    'metadata_assistant': 'healthy',
                    'content_performance_analytics': 'healthy',
                    'caching_system': 'healthy',
                    'database_connections': 'healthy'
                },
                'performance_indicators': {
                    'avg_response_time_ms': 2300,
                    'cache_hit_rate': 0.3,
                    'error_rate': 0.053,
                    'requests_per_minute': 12
                },
                'resource_usage': {
                    'memory_usage_mb': 185,
                    'cpu_usage_percent': 15,
                    'cache_size_mb': 45
                },
                'recommendations': [],
                'last_check': datetime.now().isoformat()
            }
            
            # Add recommendations based on metrics
            if health_status['performance_indicators']['error_rate'] > 0.1:
                health_status['recommendations'].append('High error rate detected - review algorithm performance')
                health_status['overall_status'] = 'warning'
            
            if health_status['performance_indicators']['cache_hit_rate'] < 0.2:
                health_status['recommendations'].append('Low cache hit rate - consider cache optimization')
            
            if not health_status['recommendations']:
                health_status['recommendations'].append('System operating normally')
            
            return jsonify({
                'success': True,
                'health': health_status,
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"Health status check error: {str(e)}")
            return jsonify({
                'success': False,
                'error': f'Health check failed: {str(e)}',
                'health': {'overall_status': 'unhealthy'},
                'timestamp': datetime.now().isoformat()
            }), 500
    
    @app.route('/api/analytics/roi-analysis', methods=['GET'])
    def get_content_roi_analysis():
        """Get content ROI analysis and optimization recommendations."""
        try:
            from metadata_assistant.analytics import ContentPerformanceAnalytics
            
            analytics_service = ContentPerformanceAnalytics(database_session=None)
            
            # Use Flask-SQLAlchemy db session
            from database import db
            analytics_service.set_database_session(db.session)
            
            # Get ROI analysis
            roi_analysis = analytics_service.get_content_roi_analysis()
            
            return jsonify({
                'success': True,
                'roi_analysis': roi_analysis,
                'timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            logger.error(f"ROI analysis error: {str(e)}")
            return jsonify({'error': f'Failed to generate ROI analysis: {str(e)}'}), 500

    @app.errorhandler(404)
    def not_found_error(error):
        """Handle 404 errors."""
        try:
            return render_template('error.html', error_message="Page not found"), 404
        except:
            return "<h1>404 - Page Not Found</h1>", 404
    
    @app.errorhandler(500)
    def internal_error(error):
        """Handle 500 errors."""
        try:
            return render_template('error.html', error_message="Internal server error"), 500
        except:
            return "<h1>500 - Internal Server Error</h1>", 500
    
    @app.errorhandler(RequestEntityTooLarge)
    def too_large_error(error):
        """Handle file too large errors."""
        return jsonify({'error': 'File too large'}), 413 